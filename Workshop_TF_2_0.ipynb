{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop_TF_2_0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "HuPOj2NK_mRt"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wgcv/TensorFlow-Taller-2.0/blob/master/Workshop_TF_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY2u15X1R8cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Por Gustavo Cevallos\n",
        "# www.wgcv.me\n",
        "# Link de este notebook bit.ly/tfgye"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KmvSKg2A6zp",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0JwvYaSBQA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![Caja Negra Modelo](https://drive.google.com/uc?id=1LEGNJi7FqEht52VtPFur8pBmbw_Uudp3)\n",
        "\n",
        "\n",
        "Es entrenar un modelo usando ejemplos y el modelo encuentra sus propias reglas, para luego poder predecir valores que no fueron entrenados.\n",
        "\n",
        "\n",
        "\n",
        "En el desarrollo de software tradicional el algoritmo es conocido, creamos una función que genera la salida esperada. En Machine Learning los valores de entrada y salidas son conocidos, pero el algortimo que genera nuestra salida no lo conocemos, entonces en Machine learning el algoritmo debe aprender como generar nuestra salida.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StjS6GIK4Ysj",
        "colab_type": "text"
      },
      "source": [
        "## Ejemplo\n",
        "\n",
        "Veamos el siguiente ejemplo\n",
        "\n",
        "![Entrada Salida](https://drive.google.com/uc?id=1Z_qB-hyjGe_C9xooh11ic_08dJhR41G3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuPOj2NK_mRt",
        "colab_type": "text"
      },
      "source": [
        "### Solución\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hccxz3UiAvL8",
        "colab_type": "text"
      },
      "source": [
        "![Funcion](https://drive.google.com/uc?id=1TTJWHL_9soRhSbr6NfTz5ti2yoy6aavN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyVc7OvrBBVR",
        "colab_type": "text"
      },
      "source": [
        "## Redes neuronales "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhVSyhb0DsCW",
        "colab_type": "text"
      },
      "source": [
        "Una red neuronal consiste de capas de una o más neuronas. Cada unidad de neurona está formada por varias entradas de diferentes pesos, estas entrada son sumadas (Una combinación lineal) y luego pasan por una función de activación y esta salida puede ser la entrada de otra neurona o la salida de la red.\n",
        "\n",
        "![Entrada Salida](https://drive.google.com/uc?id=1QCGvH7GGhY6TEMDM_a7Q9HaW7GcBkiEy)\n",
        "\n",
        "\n",
        "Matemáticamente se ve de la siguiente forma: \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
        "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "También lo podemos representar como un vector:\n",
        "\n",
        "$$\n",
        "h = \\begin{bmatrix}\n",
        "x_1 \\, x_2 \\cdots  x_n\n",
        "\\end{bmatrix}\n",
        "\\cdot \n",
        "\\begin{bmatrix}\n",
        "           w_1 \\\\\n",
        "           w_2 \\\\\n",
        "           \\vdots \\\\\n",
        "           w_n\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNgtBn5nH26j",
        "colab_type": "text"
      },
      "source": [
        "## Deep learning\n",
        "Cuando nuestra red neuronal tiene más de 2 capas (La Capa de entrada y Capa de salida ), las capas intermedias se llaman capas ocultas (Hidden Layers). Como observamos la neurona tiene dos partes una que es una función lineal y otra es la función de activación que normalmente se usa una función no lineal (Sigmoid, tanh, Softmax, ReLU) y gracias a la función de activación nuestro modelo puede aprender funciones no lineales.\n",
        "\n",
        "![Entrada Salida](https://drive.google.com/uc?id=1vpCsjfe-wMU7uv_Xu1ERrz-FHlbZKqxG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hli_iZVYRiOx",
        "colab_type": "text"
      },
      "source": [
        "## Backpropagation\n",
        "Es la propagación para atrás, una vez que nuestro modelo realiza las funciones matemáticas hasta la salida y se aplica una función de pérdida de error (Error loss) se calcula el gradiente para tunear cada uno de los pesos (Weights). El gradiente cual consiste en aplicar derivadas parciales y la regla de la cadena a cada uno de los pasos hasta llegar a la primera capa y optimizar los pesos de dicha capa. Como la primera derivada optimizamos la función de error lo que realizamos es restar dicha deriva y multiplicarla por un learning rate (El valor es  mayor a  0 y menor a 1), para que el aprendizaje sea  paulatino entre cada iteración.\n",
        "\n",
        "![Backpropagtion](https://drive.google.com/uc?id=1y60w8QdkBmdoGA9p6wNF_vMyooX1TrGx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckfta84HAz67",
        "colab_type": "text"
      },
      "source": [
        "# Framework\n",
        "\n",
        "![TensorFlow](https://drive.google.com/uc?id=1p2zAV-Xso1I07NFB-HGIW0V4_xVeM2tG)\n",
        "\n",
        "TensorFlow es una biblioteca de código abierto para machie learning, desarollado por Google y liberado en noviembre del 2015. Las ventajas de usar un framework al momento de desarrollar un proyecto de ML son muchas, entre las más importantes son: \n",
        "- No tener que implementar desde cero los conceptos báiscos.\n",
        "- Poder iterar de una forma más rápido con diferentes modelos e hiperparámetros.\n",
        "- No tener que definir la estructura de la Red neuronal y sus derivadas (Dataflow Graph).\n",
        "- Soporte para GPU.\n",
        "- Soporte de paralelismo y ejecución distribuida\n",
        "\n",
        "## Keras\n",
        "![TensorFlow](https://drive.google.com/uc?id=1eYnLxVbvMRo1724tBbUuvtPWVLMTBhWQ)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNsGUssyrq7",
        "colab_type": "text"
      },
      "source": [
        "# Nuestro primer modelo\n",
        "\n",
        "En este workshop vamos a crear un modelo que pueda predecir valor que no esten en nuestro dataset de entrenamiento y revisar los primeros pasos para usar TensorFlow y Keras. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQRA8iEKzThh",
        "colab_type": "text"
      },
      "source": [
        "## Importar las dependencias\n",
        "Lo primero que vamos hacer es importar las librerías básicas, la librería de Tensorflow como `tf` y [NumPy](http://www.numpy.org/) como `np`. Numpy es una librería que nos ayuda a manejar nuestros datos con alto desempeño."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPAKMkQFAynj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcUp4-_2-9Lp",
        "colab_type": "text"
      },
      "source": [
        "Además vamos a importar logging y configurar solo mostrar errores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiv3mFMr-6ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEZRQcmp5HkB",
        "colab_type": "text"
      },
      "source": [
        "## Nuestro Dataset\n",
        "Los modelos de Machine Learning supervisado se basan en crear el algoritmo a partir de nuestros datos de entradas y datos de salidas. Para nuestro dataset vamos a crear dos dataframes, uno de entradas que lo llamaremos `X` y otro de nuestras salidas `Y`, para entrenar nuestro modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-ro6Pt927sJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
        "y = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)\n",
        "for i,c in enumerate(X):\n",
        "  print(\"%s => %s\" %(X[i], y[i]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJpDRTnv7O6T",
        "colab_type": "text"
      },
      "source": [
        "### Terminología en Mahchine Learning\n",
        "\n",
        " - **Características** (Feature) — Puede ser uno o más valores que serán la entrada a nuestro modelo, para este ejemplo nuestra característica es solo una y esta representada por la variable `X`.\n",
        " - **Etiquetas** (Labels) — Es la salida de la predicción, que para nosotros es `Y`.\n",
        " \n",
        " - **Ejemplo** (Example) — Es una dupla de las característica y etiquetas. Por ejemplo `(-10, 14)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipgELBlf9L9z",
        "colab_type": "text"
      },
      "source": [
        "## Nuestro modelo de redes neuronales\n",
        "Vamos a crear nuestro modelo, el cual será el más sencillo una sola capa con una neurona. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0X_-JwS_Hz5",
        "colab_type": "text"
      },
      "source": [
        "## Creamos nuestra capa\n",
        "Vamos a crear nuestro modelo, el cual será el más sencillo una sola capa con una neurona. Creamos la variable `c0` instanciandola de `tf.keras.layers.Dense` con la siguiente configuración:\n",
        "- `input_shape=[1]` — Especificamos el valor de entrada de la capa, para nosotros es 1 solo valor. Si vemos la forma de nuestras características tiene un único valor de entrada por cada ejemplo.\n",
        "\n",
        "- `units=[1]` — Definimos la canitdad de neuronas en dicha capa,  como nuestro modelo solo tiene una capa tambien estaríamos definiendo la salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msb2jnfS6Vlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c0 = tf.keras.layers.Dense(units=1, input_shape=[1])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0DsFdzUAmqs",
        "colab_type": "text"
      },
      "source": [
        "## Construimos el modelo con las capas definidas\n",
        "Una vez definda las capas de nuestro modelo debemos definir nuestro modelo que pueden ser varias capas, para esto usaremos `tf.keras.Sequential` que recibe una lista ordenada de capas ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJCGLmf_-1pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = tf.keras.Sequential([c0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5oeOdrODeHA",
        "colab_type": "text"
      },
      "source": [
        "## Compilamos nuestro modelo con la función de perdida y Optimizador\n",
        "Antes de poder utilizar nuestro modelo debemos definir que función de perdida vamos a usar y como vamos a optimizar nuestro modelo.\n",
        "\n",
        "- **Función de perdida** (Loss function) — Es la forma que que tal distante estamos de la prediccióan a nuestro resultado, la diferencia de esta medida la llamamos pérdida (loss).\n",
        "\n",
        "- **Función de optimización** (Optimizer function) — La forma que logramos ajustar los pesos para que la pérdida seá menor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn3ZrdfHDccB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zOvlBfdErp3",
        "colab_type": "text"
      },
      "source": [
        "Estas dos funciones serán usadas al momento de ajustar(Fit) nuestro modelo, en el cual ingresan los ejemplso y se calcula la función de perdida y luego se optimiza los valores para obtener la pérdida mínima y se actualizan los pesos para cada uno de los ejemplos. Para este modelo usamos la función `mean_squared_error` conocida como Error cuadrático medio y el otpimizador Adam que es una versión del Gradiente descendiente Estocástico.\n",
        "\n",
        "Al momento de pasar nuestro optimizador debemos tener en cuenta el valor de ratio de aprendizaje (Learning Rate) el cual será un hiperparámetro importante que podemos tunearlo. Si tenemos un Learning Rate muy pequeño va a demorar mucho entrenar nuestro modelo, mientras que un Learning Rate muy grande no vamos a llegar nunca al mínimo de toda la función. Para este modelo vamos a usar el LR de 0.1, pero el valor defecto es 0.001\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpRGXG3xGtrv",
        "colab_type": "text"
      },
      "source": [
        "## A entrenar nuestro modelo\n",
        "Vamos a pasar nuestros ejemplos a nuestro modelo e ir aprendiendo gracias a la función de perdida y al optimizado. La primera vez que nuestro modelo corra va a iniciar con pesos (weights) aleatoreos, pero por cada vez que pasemos por nuestro modelo vamos a actualizar nuestros pesos. Las veces que pasamos nuestros ejemplos se llama epocas (epoch).\n",
        "\n",
        "Para entrenar nuestro modelo usamos el método `.fit` y pasamos nuestras características y nuestras salidas, definimos cuantas iteraciones queremos y el parámetro `verbose` es para que nos de el detalle del entrenamiento u *ocultarlo*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR10FzvYEdkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "historia = modelo.fit(X, y, epochs=500, verbose=False)\n",
        "print(\"Terminamos de entrenar el modelo\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9rNWAHsIxqh",
        "colab_type": "text"
      },
      "source": [
        "## Veamos los resultados\n",
        "El método `.fit` regresa un objeto `history` que guarda la historia del modelo durante cada época(Epoch). Entre más grande sea el valor promedio de péridada significa que más lejos estaba nuestro modelo de predecir de forma correcta.\n",
        "\n",
        "Vamos a visualizar con [Matplotlib](https://matplotlib.org/) \n",
        "Vamos a pasar nuestros ejemplos a nuestro modelo e ir aprendiendo gracias a la función de perdida y al optimizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwSrl3RcIPZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Núm. Epocas')\n",
        "plt.ylabel(\"Valor de pérdida\")\n",
        "plt.plot(historia.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Ucgc2EKF-M",
        "colab_type": "text"
      },
      "source": [
        "## A predecir valores\n",
        "Ahora que tenemos el modelo y se encuentra entrenado, podemos predecir valores desconocidos. \n",
        "Veamos cuanto es el valor si nuestra entrada es 120."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Fi5xHaJtNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(modelo.predict([120.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2GE0i-WK0s7",
        "colab_type": "text"
      },
      "source": [
        "El resultado esperado es 248, pero nuestro modelo nos predijo con una diferencia de ±0.3 de error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFS7OpZ8O6bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(modelo.predict([-10.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CELE1gbZLxi_",
        "colab_type": "text"
      },
      "source": [
        "## ¿Que modelo creamos?\n",
        "Veamos nuestros valores de entradas y salidas, también podemos calcular lineal con la formula $y = mx + b$. \n",
        "\n",
        "*¿Qué función lineal que conocemos representa nuestro modelo?*\n",
        "\n",
        "Si necesitamos otra pista podemos ver las variables de nuestras capas con `.get_weights()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX6pqUAmKrGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Pesos (Weights): %F\\nSesgo(bias):%F\" %(c0.get_weights()[0],c0.get_weights()[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTMKJX4FOChG",
        "colab_type": "text"
      },
      "source": [
        "# Resumen\n",
        "- Aprendimos los conceptos básicos de las redes neuronales\n",
        "- Creamos una red de una capa totalmente conectada (Fully connected o dense layer)\n",
        "- Entrenamos nuestra red con 3500 ejemplos (7 pares por 500 veces)\n",
        "\n",
        "## Juega con el modelo\n",
        "Ahora te toca a tí modificar el modelo, puedes: crear más capas, cambia las épocas (Epochs) y tambien aumentar o reducir la canitdad de ejemplos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guKNt_xp9bU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}